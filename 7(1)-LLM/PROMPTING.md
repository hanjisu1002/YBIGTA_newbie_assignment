# Prompting Method에 따른 정확도 비교 표

| Prompting Method | 0-shot Accuracy | 3-shot Accuracy | 5-shot Accuracy |
|------------------|------------------|------------------|------------------|
| Direct Prompting | 0.16             | 0.16             | 0.18             |
| CoT Prompting    | 0.720            | 0.680            | 0.700            |
| My Prompting     | 0.820            | 0.760            | 0.740            |


# CoT Prompting이 Direct Prompting보다 나은 이유
CoT (Chain-of-Thought) 프롬팅은 모델이 문제를 해결할 때 단순히 정답만을 도출하는 것이 아니라, 중간 추론 과정을 단계적으로 언어화하도록 유도하는 방식입니다. 
즉, 모델이 문제를 푸는 과정을 사람이 손으로 풀 듯 자연어로 표현하게 만들어 각 단계의 논리적 타당성을 확인할 수 있는 구조입니다.
따라서 모델이 답변 도출 과정을 검증할 수 있고 주어진 답변들의 흐름을 확인하며 최종 결론에 도달하기 때문에 추론 과정을 거치지 않는 답변 생성 과정보다 정확도가 상승합니다. 

반면, Direct Prompting은 문제에 대해 바로 최종 정답만을 출력하도록 유도하기 때문에, 중간 사고 과정이 생략되고 그에 따라 논리적 오류나 계산 실수의 가능성이 더 커지게 됩니다. 특히, 수학 문제나 조건이 여러 단계로 연결된 문제와 같이 단계적 사고 또는 복잡한 추론이 필요한 경우에는 Direct Prompting 방식만을 사용하였을 때 정답률이 급격히 낮게 나타나는 경향이 있습니다.

CoT 방식은 이러한 한계를 극복하고자 고안된 것으로, 모델이 스스로 사고의 흐름을 언어적으로 구조화하도록 함으로써 문제 해결의 일관성과 정확성을 높일 수 있습니다. 각 단계의 출력이 명시되기 때문에 오류를 추적하거나 검토하기도 쉬워진다는 장점 또한 존재합니다. 

실제로 본 실험에서도 CoT Prompting을 적용했을 때 Direct Prompting에 비해 정답률이 크게 향상되었으며, 이는 복잡한 문제일수록 더욱 두드러지는 것으로 알고 있습니다.  따라서 CoT 프롬팅은 단순 정답 생성이 아닌, 사고 과정 자체를 강화하는 효과적인 프롬프트 기법으로 볼 수 있습니다.

# My prompt 기법이 CoT보다 높은 성능을 보일 수 있었던 이유
성능을 높이기 위해 프롬프트 기법을 고안하며, CoT 방식의 장점을 유지하면서 추가 정답 검증 단계를 도입하여 정확도를 더욱 향상시키는데 집중했습니다. 

제가 고안한 방법에서는 모델이 처음에 Scratchpad 라는 공간에 reasoning을 먼저 수행하여 Chain-of-Thought 방식으로 문제를 해결한 후, 해당 결과가 올바른지 다시 검토하는 단계(Verification)를 수행합니다. 
결과에 대해 판단하는 prompt 예시들을 example_list에 넣고, 이러한 예시들을 참고하여 모델이 생성한 답변에 대해 답변을 한번 더 생성하도록 하였습니다. 

처음에는 논리적 추론 과정을 검증하는 프롬프트를 넣고 틀렸을 경우 답변을 다시 생성하도록 고안하였으나, 모델의 성능이 이 정도의 추론 검증을 수행하면서 오히려 감소하였습니다. 
또한 self-consistency 방식도 적용해보았으나 생성되는 답변 자체의 정답률이 높지 않아서 오히려 여러 번 답변 생성 후 가장 빈도가 높은 답변을 선택할 시 정답이 아닌 답변을 선택하는 경우가 늘어 성능이 감소하는 모습을 보였습니다. 이러한 방식으로 추론을 검증하기 위해서는 좀 더 parameter scale이 큰 모델이 필요할 것 같습니다. 

최종적으로 선택한 구조는 CoT만 사용하는 방식이 가진 단점 - 즉, 중간 추론이 있어도 최종 답이 틀릴 수 있는 문제를 보완합니다. 따라서 모델이 답변을 한번 더 생성하고 그 답변을 최종 답변으로 선택하여 좀 더 신뢰도 높은 답을 생성하게 만들고, 실험에서도 CoT 대비 더 높은 정확도를 달성했습니다.